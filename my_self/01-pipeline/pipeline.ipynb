{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c6aa0",
   "metadata": {},
   "source": [
    "# Êü•ÁúãPipelineÊîØÊåÅÁöÑ‰ªªÂä°Á±ªÂûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b5e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\envs\\transformers\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d140d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification audio\n",
      "automatic-speech-recognition multimodal\n",
      "text-to-audio text\n",
      "feature-extraction multimodal\n",
      "text-classification text\n",
      "token-classification text\n",
      "question-answering text\n",
      "table-question-answering text\n",
      "visual-question-answering multimodal\n",
      "document-question-answering multimodal\n",
      "fill-mask text\n",
      "summarization text\n",
      "translation text\n",
      "text2text-generation text\n",
      "text-generation text\n",
      "zero-shot-classification text\n",
      "zero-shot-image-classification multimodal\n",
      "zero-shot-audio-classification multimodal\n",
      "image-classification image\n",
      "image-feature-extraction image\n",
      "image-segmentation multimodal\n",
      "image-to-text multimodal\n",
      "image-text-to-text multimodal\n",
      "object-detection multimodal\n",
      "zero-shot-object-detection multimodal\n",
      "depth-estimation image\n",
      "video-classification video\n",
      "mask-generation multimodal\n",
      "image-to-image image\n",
      "keypoint-matching image\n"
     ]
    }
   ],
   "source": [
    "for k , v in SUPPORTED_TASKS.items():\n",
    "    print(k,v['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888b20e",
   "metadata": {},
   "source": [
    "# Pipeline ÁöÑÂàõÂª∫‰∏é‰ΩøÁî®ÊñπÂºè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b7e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n",
      "üö® Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n",
      "üö® Config not found for parakeet. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/auto_docstring.py\n"
     ]
    }
   ],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82f5e4",
   "metadata": {},
   "source": [
    "# Ê†πÊçÆ‰ªªÂä°Á±ªÂûãÁõ¥Êé•ÂàõÂª∫pipelineÔºåÈªòËÆ§ÈÉΩÊòØËã±ÊñáÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47975438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\model.safetensors\n",
      "Since the `dtype` attribute can't be found in model's config object, will use dtype={dtype} as derived from model's weights\n",
      "Instantiating DistilBertForSequenceClassification model under default dtype torch.float32.\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\714eb0fa89d2f80546fda750413ed43d93601a13\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb0b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998520612716675}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('very good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a05d34",
   "metadata": {},
   "source": [
    "# ÊåáÂÆö‰ªªÂä°Á±ªÂûãÔºåÂÜçÊåáÂÆöÊ®°ÂûãÔºåÂàõÂª∫Âü∫‰∫éÊåáÂÆöÊ®°ÂûãÁöÑPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c759ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\pytorch_model.bin\n",
      "Since the `dtype` attribute can't be found in model's config object, will use dtype={dtype} as derived from model's weights\n",
      "Instantiating BertForSequenceClassification model under default dtype torch.float32.\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-classification',model='uer/roberta-base-finetuned-dianping-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb145ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative (stars 1, 2 and 3)', 'score': 0.9743660688400269}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('ÊàëËßâÂæó‰∏çÂ§™Ë°å')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a3209",
   "metadata": {},
   "source": [
    "# È¢ÑÂÖàÂä†ËΩΩÊ®°ÂûãÔºåÂÜçÂàõÂª∫Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb741a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\pytorch_model.bin\n",
      "Safetensors PR exists\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')\n",
    "tokenizer = AutoTokenizer.from_pretrained('uer/roberta-base-finetuned-dianping-chinese')\n",
    "pipe = pipeline('text-classification',model =model,tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f41d834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative (stars 1, 2 and 3)', 'score': 0.9743660688400269}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to create safetensors variant\n"
     ]
    }
   ],
   "source": [
    "pipe('ÊàëËßâÂæó‰∏çÂ§™Ë°å')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef34cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b991f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Safetensors PR exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015119900703430176\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "times = []\n",
    "for i in range(100):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    pipe(\"ÊàëËßâÂæó‰∏çÂ§™Ë°åÔºÅ\")\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "print(sum(times) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39722ac",
   "metadata": {},
   "source": [
    "# ‰ΩøÁî®GPUËøõË°åÊé®ÁêÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108f46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-classification',model =model,tokenizer=tokenizer,device = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9557b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015259256362915039\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "times = []\n",
    "for i in range(100):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    pipe(\"ÊàëËßâÂæó‰∏çÂ§™Ë°åÔºÅ\")\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "print(sum(times) / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42fb85",
   "metadata": {},
   "source": [
    "# Á°ÆÂÆöpipelineÂèÇÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f911fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\pytorch_model.bin\n",
      "Since the `dtype` attribute can't be found in model's config object, will use dtype={dtype} as derived from model's weights\n",
      "Instantiating BertForQuestionAnswering model under default dtype torch.float32.\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Safetensors PR exists\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"auto\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"auto\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-chinese-extractive-qa\\snapshots\\9b02143727b9c4655d18b43a69fc39d5eb3ddd53\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "qa_pipe = pipeline(\"question-answering\", model=\"uer/roberta-base-chinese-extractive-qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44ada62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x12b4cfe3fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a012f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.question_answering.QuestionAnsweringPipeline"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.question_answering.QuestionAnsweringPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6ab50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7320808172225952, 'start': 6, 'end': 8, 'answer': 'Âåó‰∫¨'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pipe(question=\"‰∏≠ÂõΩÁöÑÈ¶ñÈÉΩÊòØÂì™ÈáåÔºü\", context=\"‰∏≠ÂõΩÁöÑÈ¶ñÈÉΩÊòØÂåó‰∫¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f29e10",
   "metadata": {},
   "source": [
    "# pipelineËÉåÂêéÁöÑÂÆûÁé∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccccf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cbdda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative (stars 1, 2 and 3)\",\n",
      "    \"1\": \"positive (stars 4 and 5)\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative (stars 1, 2 and 3)\": 0,\n",
      "    \"positive (stars 4 and 5)\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--uer--roberta-base-finetuned-dianping-chinese\\snapshots\\25faf1874b21e76db31ea9c396ccf2a0322e0071\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f74abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769, 6230, 2533,  679, 1922, 6121, 8013,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"ÊàëËßâÂæó‰∏çÂ§™Ë°åÔºÅ\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96227828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.7376, -1.8681]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(**inputs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2c5b015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9736, 0.0264]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = res.logits\n",
    "logits = torch.softmax(logits, dim=-1)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11e86efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.argmax(logits).item()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "289cc6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative (stars 1, 2 and 3)', 1: 'positive (stars 4 and 5)'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd23619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative (stars 1, 2 and 3)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.config.id2label.get(pred)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
