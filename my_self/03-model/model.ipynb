{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087b65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab10f0d",
   "metadata": {},
   "source": [
    "# 模型加载与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6c66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fda73",
   "metadata": {},
   "source": [
    "# 在线加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50db5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\",force_download=True,cache_dir='./rbt3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fbab3",
   "metadata": {},
   "source": [
    "# 离线加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135e3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一定要是有config.json、pytorch_model.bin 的文件夹\n",
    "model = AutoModel.from_pretrained('./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3b246",
   "metadata": {},
   "source": [
    "# 模型加载参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee851d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179cd6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"dtype\": \"float32\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309947e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c')\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b3784",
   "metadata": {},
   "source": [
    "# 模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af59b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 3457, 2682, 8013,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '弱小的我也有大梦想！'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "inputs = tokenizer(sen,return_tensors = 'pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919765b0",
   "metadata": {},
   "source": [
    "# 不带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc015884",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d6636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6804,  0.6664,  0.7170,  ..., -0.4102,  0.7839, -0.0262],\n",
       "         [-0.7378, -0.2748,  0.5034,  ..., -0.1359, -0.4331, -0.5874],\n",
       "         [-0.0212,  0.5642,  0.1032,  ..., -0.3617,  0.4646, -0.4747],\n",
       "         ...,\n",
       "         [ 0.0853,  0.6679, -0.1757,  ..., -0.0942,  0.4664,  0.2925],\n",
       "         [ 0.3336,  0.3224, -0.3355,  ..., -0.3262,  0.2532, -0.2507],\n",
       "         [ 0.6761,  0.6688,  0.7154,  ..., -0.4083,  0.7824, -0.0224]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.2646e-01, -9.8619e-01, -1.0000e+00, -9.8325e-01,  8.0238e-01,\n",
       "         -6.6268e-02,  6.6919e-02,  1.4784e-01,  9.9451e-01,  9.9995e-01,\n",
       "         -8.3051e-02, -1.0000e+00, -9.8866e-02,  9.9980e-01, -1.0000e+00,\n",
       "          9.9993e-01,  9.8291e-01,  9.5363e-01, -9.9948e-01, -1.3219e-01,\n",
       "         -9.9733e-01, -7.7934e-01,  1.0720e-01,  9.8040e-01,  9.9953e-01,\n",
       "         -9.9939e-01, -9.9997e-01,  1.4967e-01, -8.7627e-01, -9.9996e-01,\n",
       "         -9.9821e-01, -9.9999e-01,  1.9396e-01, -1.1277e-01,  9.9359e-01,\n",
       "         -9.9153e-01,  4.4752e-02, -9.8731e-01, -9.9942e-01, -9.9982e-01,\n",
       "          2.9360e-02,  9.9847e-01, -9.2014e-03,  9.9999e-01,  1.7111e-01,\n",
       "          4.5077e-03,  9.9998e-01,  9.9467e-01,  4.9727e-03, -9.0707e-01,\n",
       "          6.9056e-02, -1.8141e-01, -9.8831e-01,  9.9668e-01,  4.9800e-01,\n",
       "          1.2997e-01,  9.9895e-01, -1.0000e+00, -9.9990e-01,  9.9478e-01,\n",
       "         -9.9989e-01,  9.9906e-01,  9.9820e-01,  9.9990e-01, -6.8953e-01,\n",
       "          9.9990e-01,  9.9987e-01,  9.4563e-01, -3.7660e-01, -1.0000e+00,\n",
       "          1.3151e-01, -9.7371e-01, -9.9997e-01, -1.3228e-02, -2.9800e-01,\n",
       "         -9.9985e-01,  9.9662e-01, -2.0004e-01,  9.9997e-01,  3.6876e-01,\n",
       "         -9.9997e-01,  1.5462e-01,  1.9265e-01,  8.9872e-02,  9.9996e-01,\n",
       "          9.9998e-01,  1.5184e-01, -8.9714e-01, -2.1645e-01, -9.9922e-01,\n",
       "         -4.9491e-01,  9.9957e-01,  9.9998e-01, -9.9998e-01,  9.9995e-01,\n",
       "         -5.1678e-01,  5.2055e-02,  5.4613e-02, -9.9816e-01,  9.9328e-01,\n",
       "          1.2707e-04, -1.3744e-01,  1.0000e+00,  9.9984e-01, -3.4417e-01,\n",
       "         -9.9995e-01, -9.9573e-01,  9.9988e-01, -9.9981e-01,  6.3345e-02,\n",
       "          1.0000e+00,  9.4779e-01,  1.0000e+00,  9.9946e-01,  9.9999e-01,\n",
       "         -9.9999e-01, -4.3540e-01,  2.3526e-01, -9.9997e-01,  9.9905e-01,\n",
       "         -9.9272e-01,  1.4150e-01, -9.3078e-01, -8.8246e-02, -1.2646e-02,\n",
       "         -9.9999e-01,  1.8302e-02,  3.9717e-02, -9.8869e-01, -9.9944e-01,\n",
       "         -9.9975e-01, -9.9994e-01,  9.9785e-01,  7.9386e-01,  2.7185e-01,\n",
       "         -1.5316e-01,  9.0940e-02, -9.5427e-02, -1.0000e+00, -9.9974e-01,\n",
       "         -9.9999e-01,  9.5742e-01, -3.5169e-01,  9.9779e-01, -9.9894e-01,\n",
       "          9.9997e-01, -9.9997e-01,  9.9997e-01,  9.9414e-01, -2.7013e-01,\n",
       "         -9.7769e-01, -1.1832e-01, -9.9976e-01, -4.3268e-02,  2.7016e-02,\n",
       "          9.9011e-01,  9.9801e-01,  7.6135e-01, -9.8868e-01,  1.0000e+00,\n",
       "         -9.9946e-01,  9.7542e-01,  1.4209e-01,  9.9955e-01,  1.0000e+00,\n",
       "         -1.0000e+00,  2.5602e-01, -1.0000e+00,  6.9886e-01,  1.1957e-01,\n",
       "          9.9996e-01,  9.9962e-01,  9.7632e-01,  9.9998e-01, -8.6662e-01,\n",
       "         -9.9994e-01,  9.5777e-01, -1.0000e+00,  9.8048e-01,  1.0000e+00,\n",
       "          9.6254e-02,  5.4608e-01,  9.9999e-01, -6.1723e-01,  9.9141e-01,\n",
       "         -1.0398e-01, -1.9344e-01, -9.9981e-01,  2.0875e-01,  9.4846e-01,\n",
       "          9.9600e-01, -9.9833e-01, -3.6391e-02,  9.8665e-01, -3.1239e-02,\n",
       "          6.7723e-02, -9.9968e-01, -9.9970e-01,  9.9994e-01,  9.9983e-01,\n",
       "          6.2746e-01, -2.7500e-01,  1.0000e+00, -1.1557e-01,  9.9997e-01,\n",
       "         -7.4189e-02,  8.3064e-01, -8.6326e-02,  9.9989e-01,  1.6120e-01,\n",
       "          8.7417e-01,  4.2873e-03,  9.9993e-01, -8.4737e-01, -9.9999e-01,\n",
       "          8.9603e-02,  8.9435e-01,  1.0934e-01, -9.9877e-01,  2.1512e-01,\n",
       "         -4.4630e-01,  9.9997e-01,  1.9113e-01, -9.8081e-01,  9.9929e-01,\n",
       "         -9.9977e-01,  6.1149e-01, -1.0000e+00, -9.9892e-01,  9.9998e-01,\n",
       "         -2.9081e-01, -1.0000e+00,  8.6111e-01,  1.0000e+00, -8.8875e-01,\n",
       "          9.9958e-01, -2.4632e-01, -9.9994e-01, -1.4218e-02,  3.7027e-02,\n",
       "         -1.0000e+00, -9.9450e-01, -1.0000e+00, -8.2727e-01, -1.4345e-01,\n",
       "          9.9392e-01, -1.0000e+00,  1.1743e-01, -9.9999e-01,  9.9873e-01,\n",
       "          9.9997e-01, -1.5349e-01,  1.7382e-01,  1.0000e+00, -3.5095e-01,\n",
       "          1.3408e-01, -8.4305e-01,  3.7473e-01,  2.2783e-02,  9.9625e-01,\n",
       "          3.2440e-01,  9.9899e-01, -9.9979e-01,  2.4282e-01,  8.5081e-01,\n",
       "         -1.0000e+00, -1.0721e-01,  9.9331e-01,  2.8107e-02,  1.0824e-01,\n",
       "         -1.8632e-01,  1.7009e-01,  9.5663e-01,  9.9947e-01,  1.0000e+00,\n",
       "          9.9177e-01,  9.9999e-01,  9.9999e-01, -3.1200e-01, -9.9837e-01,\n",
       "         -5.6503e-01,  2.3465e-01, -1.0000e+00, -9.8613e-01, -9.9979e-01,\n",
       "          9.9075e-01,  1.1560e-01,  1.0000e+00, -1.0000e+00,  1.0000e+00,\n",
       "         -9.6587e-01,  8.5970e-02, -5.3795e-02,  1.2931e-01, -5.4356e-01,\n",
       "         -1.2560e-01,  9.9880e-01, -7.6849e-02,  9.9302e-01,  9.9631e-01,\n",
       "         -4.9744e-03, -2.4950e-01,  2.0312e-01, -2.2919e-01,  9.9857e-01,\n",
       "         -9.9750e-01,  9.9836e-01,  1.0468e-01,  9.9982e-01, -4.5313e-01,\n",
       "         -1.0000e+00,  9.9977e-01, -9.9988e-01, -5.4165e-01, -9.9991e-01,\n",
       "         -9.8466e-01,  9.0575e-02, -9.8760e-01,  7.2146e-01,  9.9684e-01,\n",
       "          2.2268e-01,  1.4701e-01, -9.9999e-01, -9.6879e-01,  9.9483e-01,\n",
       "          9.9992e-01, -9.9977e-01,  9.9892e-01,  9.9656e-01, -9.3349e-01,\n",
       "          2.5862e-01,  9.7359e-01, -9.9937e-01,  9.8777e-01, -9.9999e-01,\n",
       "          1.1818e-01,  9.9960e-01, -1.7951e-01, -9.9984e-01, -9.2495e-01,\n",
       "         -2.2660e-02,  7.8255e-01, -2.6023e-02,  9.9999e-01, -1.2445e-02,\n",
       "          1.5701e-01, -9.9998e-01, -9.9624e-01, -8.6672e-01,  3.4873e-01,\n",
       "          9.9931e-01, -9.9999e-01, -6.6311e-02,  9.9949e-01, -9.9926e-01,\n",
       "         -4.1633e-01,  4.3388e-02,  8.4618e-02, -8.7278e-02, -9.9765e-01,\n",
       "         -9.9999e-01, -9.9998e-01,  9.9993e-01,  1.0225e-01, -5.4235e-04,\n",
       "          9.9924e-01,  9.9998e-01,  9.9997e-01, -9.8936e-01,  9.3540e-01,\n",
       "          9.9986e-01, -3.1887e-01,  1.1548e-01, -9.8294e-01,  1.4084e-01,\n",
       "         -8.1032e-01, -9.9606e-01,  1.2704e-01,  2.7952e-01, -6.5889e-01,\n",
       "         -9.9392e-01,  9.9999e-01,  9.9994e-01,  1.0000e+00, -1.0210e-01,\n",
       "         -9.4733e-01,  8.3178e-01, -9.4359e-01, -9.9962e-01, -4.4847e-02,\n",
       "          9.9938e-01, -9.9812e-01,  1.7198e-01,  7.5851e-02, -9.4664e-01,\n",
       "          9.9917e-01, -9.9949e-01,  1.5547e-01, -1.0000e+00, -9.9998e-01,\n",
       "         -9.9998e-01,  1.0000e+00,  9.2368e-02, -1.2598e-01, -9.9929e-01,\n",
       "          1.0000e+00,  9.8569e-01, -9.6164e-01, -2.5984e-01,  9.9998e-01,\n",
       "         -4.7267e-01, -8.6810e-01, -1.0000e+00, -9.9985e-01,  9.9819e-01,\n",
       "          1.2791e-01,  9.9999e-01,  8.4013e-01, -9.9762e-01,  9.8651e-01,\n",
       "          9.7417e-01,  3.1610e-01, -9.9945e-01, -9.9936e-01, -3.3197e-03,\n",
       "          7.0084e-02,  1.5902e-01,  9.8474e-03, -5.9952e-02,  9.9992e-01,\n",
       "         -3.2019e-02, -9.5302e-02, -3.2294e-01,  1.0000e+00,  8.7427e-01,\n",
       "         -9.9866e-01, -6.7442e-01, -8.8977e-02, -9.9465e-01, -9.9605e-01,\n",
       "         -9.9996e-01, -2.6155e-01,  1.4165e-01,  4.0373e-02, -9.9220e-01,\n",
       "         -9.9825e-01, -9.9979e-01,  1.5164e-02, -9.9095e-01, -9.9897e-01,\n",
       "         -1.5214e-01, -9.9863e-01, -9.9987e-01,  9.9998e-01, -9.9994e-01,\n",
       "         -6.0611e-03,  9.7556e-01,  9.9935e-01, -9.9990e-01,  2.1632e-01,\n",
       "          9.9836e-01, -9.9856e-01,  2.3167e-01, -9.8543e-01, -2.4209e-03,\n",
       "         -8.9389e-01, -1.0000e+00,  3.3006e-01,  9.9995e-01,  9.9989e-01,\n",
       "          9.9846e-01,  9.1860e-01, -7.6863e-01,  9.6949e-01,  9.9988e-01,\n",
       "          1.0000e+00, -8.6599e-02, -1.3680e-01, -9.9999e-01, -6.0014e-01,\n",
       "          8.4746e-01,  1.0654e-01,  8.5102e-01, -9.9990e-01,  3.2253e-01,\n",
       "         -9.2435e-01,  2.9811e-01,  1.0000e+00,  9.9763e-01,  1.9317e-01,\n",
       "         -1.0000e+00,  2.9202e-01, -5.9693e-01,  2.1347e-01, -9.9327e-01,\n",
       "         -1.2919e-02,  1.0000e+00, -9.6718e-01,  2.9585e-01, -9.9959e-01,\n",
       "         -9.9972e-01,  9.9999e-01, -9.9997e-01,  9.9999e-01,  9.3987e-01,\n",
       "         -9.9433e-01, -2.2040e-01, -9.8471e-01, -5.8420e-02, -1.5101e-02,\n",
       "         -1.0072e-01, -3.6830e-01, -8.9497e-02, -1.0000e+00,  1.3947e-01,\n",
       "          9.8818e-01,  3.1653e-02, -1.7422e-01, -9.9989e-01,  2.3496e-01,\n",
       "          9.7184e-01, -9.9993e-01, -9.9996e-01, -1.7622e-01, -4.5059e-01,\n",
       "          1.3080e-01, -1.9687e-02, -4.3434e-02, -1.0662e-02, -9.9764e-01,\n",
       "          5.8260e-02,  9.8391e-01, -9.9202e-01,  8.4339e-01, -8.8047e-01,\n",
       "         -9.1329e-01, -2.2054e-01,  9.9995e-01,  9.9985e-01, -9.9992e-01,\n",
       "         -9.9973e-01, -4.1531e-01,  5.9139e-02, -7.8567e-01,  9.9938e-01,\n",
       "          1.0516e-01, -9.9878e-01,  2.1823e-01,  1.8433e-01, -2.5135e-01,\n",
       "         -8.3777e-01,  1.0000e+00, -9.9484e-01,  1.0000e+00, -1.0000e+00,\n",
       "         -9.6393e-01,  1.9465e-01,  9.9998e-01, -9.9999e-01, -1.9518e-01,\n",
       "          9.9966e-01, -1.0000e+00, -2.9225e-02, -9.4787e-01,  8.8237e-01,\n",
       "         -3.2163e-02,  7.1631e-02,  7.8673e-01, -9.9974e-01,  1.6660e-01,\n",
       "         -9.9982e-01,  9.5086e-01,  9.9166e-01, -9.9993e-01, -6.1025e-01,\n",
       "         -9.9999e-01, -5.4383e-02,  6.0816e-02, -9.9975e-01,  9.9869e-01,\n",
       "          9.9999e-01, -4.4476e-02,  8.5795e-01, -9.9980e-01,  4.4506e-03,\n",
       "         -3.0101e-01, -9.8803e-01,  5.4812e-02, -9.9990e-01,  9.6314e-01,\n",
       "         -9.9127e-01,  9.9875e-01, -1.0000e+00,  9.8999e-01,  9.9710e-01,\n",
       "         -3.8264e-02, -6.5084e-01,  3.6453e-02,  4.2460e-01, -9.9999e-01,\n",
       "         -4.0224e-02, -9.9980e-01, -9.9983e-01,  2.8015e-01,  9.9988e-01,\n",
       "          9.9221e-01,  2.0411e-01,  9.9606e-01, -9.9796e-01, -2.8134e-02,\n",
       "          3.2979e-01,  6.6948e-01,  1.0000e+00, -9.9960e-01, -9.9993e-01,\n",
       "          9.9783e-01, -9.9996e-01, -9.9582e-01,  1.0000e+00,  1.0809e-01,\n",
       "          9.9989e-01, -2.8598e-02, -9.9971e-01,  1.2306e-01,  1.1798e-01,\n",
       "          9.9988e-01, -6.1641e-02, -1.1223e-01,  9.9997e-01, -1.1004e-01,\n",
       "          4.9045e-02, -6.0948e-01,  9.8479e-01, -2.3674e-01, -1.3137e-01,\n",
       "          9.9882e-01, -9.8893e-01, -9.9954e-01, -9.9989e-01,  1.8203e-01,\n",
       "          2.8674e-02,  4.0661e-02,  4.1384e-02,  8.4515e-01,  9.9998e-01,\n",
       "         -9.9956e-01,  9.9718e-01, -1.0000e+00, -9.9996e-01,  3.4786e-02,\n",
       "          1.6964e-01,  9.9935e-01, -9.4625e-02, -9.9383e-01,  1.3268e-01,\n",
       "         -9.8623e-01,  9.9770e-01, -9.9977e-01,  9.7668e-01, -1.0568e-01,\n",
       "          2.1731e-01,  9.9997e-01,  9.9913e-01, -3.6219e-02, -9.9880e-01,\n",
       "         -7.8271e-01, -2.8410e-02, -9.9888e-01,  9.9994e-01,  1.5550e-01,\n",
       "          1.9994e-01,  8.1394e-02,  1.4413e-03, -9.9998e-01, -9.9339e-01,\n",
       "          1.2288e-01,  9.9966e-01, -9.9993e-01,  9.9627e-01, -9.8925e-01,\n",
       "          9.9995e-01,  9.9989e-01,  1.0000e+00,  8.2978e-02,  9.9106e-01,\n",
       "         -9.9995e-01, -9.9636e-01,  9.7994e-01,  9.9933e-01,  1.0000e+00,\n",
       "          9.9820e-01,  9.7212e-01,  4.1774e-02, -9.9998e-01,  9.5319e-01,\n",
       "         -2.1234e-01, -2.5803e-01,  4.4171e-02, -9.7493e-01, -9.9998e-01,\n",
       "          9.9999e-01, -9.9999e-01, -9.9998e-01, -9.7688e-01, -9.9998e-01,\n",
       "          9.9955e-01,  6.3524e-01,  9.9913e-01,  8.2837e-01, -9.9992e-01,\n",
       "         -9.9911e-01, -7.4413e-02, -9.8721e-01, -9.9601e-01,  7.3157e-02,\n",
       "         -1.0000e+00,  4.0977e-02,  1.5363e-01, -9.5962e-01, -9.4313e-02,\n",
       "         -9.0655e-01, -1.2196e-01,  9.9709e-01,  6.6145e-01,  9.8879e-01,\n",
       "         -9.9556e-01, -9.9926e-01,  1.6966e-01, -1.0000e+00,  9.9555e-01,\n",
       "          9.9994e-01, -1.2530e-01,  9.5008e-01, -9.6306e-01,  1.6588e-01,\n",
       "         -1.0000e+00, -1.0000e+00,  9.7010e-01,  9.9986e-01,  3.6408e-03,\n",
       "         -9.9972e-01,  3.5594e-02, -9.9921e-01, -1.7513e-01,  9.5917e-01,\n",
       "          9.9811e-01, -9.9906e-01,  9.9963e-01, -9.9253e-01, -2.0149e-02,\n",
       "          9.9336e-01, -1.0000e+00,  8.5619e-01, -9.9406e-01,  1.0000e+00,\n",
       "         -1.0000e+00,  9.9858e-01, -4.8630e-01, -1.0990e-01, -1.3153e-02,\n",
       "          8.8953e-01, -9.9992e-01, -2.2119e-01,  9.9139e-01,  9.8939e-01,\n",
       "          6.7299e-03,  9.9942e-01, -1.8233e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a97345e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9bd384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6c3ea",
   "metadata": {},
   "source": [
    "# 带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b7346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b879cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained('./rbt3/models--hfl--rbt3/snapshots/0aa0527ff4170f29e1dfd3eb6ef60dc67e1bf75c', num_labels=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4335e97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ee495f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4536, -0.1164,  0.3103, -0.0170, -0.6026, -0.5078,  0.4890, -0.1149,\n",
       "          0.3790,  0.3096]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "037e31ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model.config.num_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
